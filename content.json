[{"title":"Adam Optimization 简介","date":"2017-06-26T13:10:10.000Z","path":"2017/06/26/Adam-Optimizer-简介/","text":"本文介绍了Adam Optimization参考了论文ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION，并介绍了几种优化方法的优劣。 背景Gradient Descent取损失函数（loss function）的梯度如$(1)$式所示：$$\\begin{equation}g_t = \\nabla_\\theta L_t(\\theta_{t-1};x;y)\\label{eq:1}\\end{equation}$$ 损失函数是权重$\\theta$的函数，每次计算都将整个训练集$(x,y)$输入到损失函数中。每次迭代的步骤为：$$ \\begin{equation}\\theta_{t} = \\theta_{t-1} - \\alpha\\cdot g_t\\label{eq:2}\\end{equation}$$保证了$\\theta$沿梯度的方向下降$\\alpha$，但是这种方法有着明显的缺点： 当数据集过大时，每一次都将整个数据集计算一遍梯度回传是非常耗时的，而且一般无法将整个数据集都放到内存当中学习率$\\alpha$是一个超参数，需要人为设置算法容易得到局部最优解 Mini-batch Gradient Descent因为取整个数据集是不明智的，所以在计算梯度时，取数据集的一部分，如$(3)$式所示：$$ \\begin{equation}g_t = \\nabla_\\theta f_t(\\theta _{t-1};x^{(i:i+n)};y^{(i:i+n)})\\label{eq:3}\\end{equation}$$这样做的好处在于简化了计算梯度的过程，同时因为一部分数据的局部最优解不一定是另一部分数据的局部最优解，所以不一定会使算法停在部分局部最优解上。但它也有较严重的缺点： 由于随机取数据集，可能导致梯度的噪声非常大，使算法收敛的速率很慢容易停在满足整体数据集的局部最优解上 Momentum利用物理中动量的概念，但是我个人认为更接近于速度的概念，即将每部的梯度当成加速度，而不是之前的速度，这样使得噪声很大的随机梯度可以变得平滑，同时由于梯度为加速度，可以使算法收敛的更快，且可以越过一些局部最优解。动量公式以及迭代公式如$(4)$、$(5)$式所示：$$ \\begin{equation}m_t = \\mu \\cdot m_{t-1} + g_t\\label{eq:4}\\end{equation}$$ $$ \\begin{equation}\\theta_t = \\theta_{t-1} - \\alpha \\cdot m_t\\label{eq:5}\\end{equation}$$它的缺点也是显而易见的： 需要规定超参数$\\mu$和$\\alpha$，即不能自适应的调节超参数，可能会使$\\theta$的移动方向偏移梯度下降的主方向，从而没有那么快速地收敛 AdagradAdagrad引入了梯度$g_t$的平方和作为对学习率的约束，从而达到自适应的效果。$$ \\begin{equation}n_t = n_{t-1} + g_t^2\\label{eq:6}\\end{equation}$$ $$ \\begin{equation}\\theta_t = \\theta_{t-1} - \\frac{\\alpha}{\\sqrt{n_t + \\epsilon}} \\cdot g_t\\label{eq:7}\\end{equation}$$从式$(7)$可以看出，越到后期平方和越大，移动的步长越小，适用于处理稀疏梯度问题，但是不知道是什么原因，缺点为： 仍然有一个超参数，并且超参数的设置对自适应系数的影响比较大在中后期，平方和越来越大，有可能使训练提前结束 Adadelta对平方和做了优化，使其为梯度的二阶矩的期望，但是是有偏期望。如式$(8)$：$$ \\begin{equation}\\mathbb{E}[g_t^2] = \\beta_2\\cdot \\mathbb{E}[g_{t-1}^2]+(1-\\beta_2)\\cdot g_t^2\\label{eq:8}\\end{equation}$$这样解决了后期算法提前结束的问题，同时为了自适应学习率，Adadelta采用了步长相加的方式，类似于动量的形式：$$ \\begin{equation}\\Delta \\theta_t = - \\frac{\\sqrt{\\mathbb{E}[\\Delta \\theta_{t-1}^2]+\\epsilon}}{\\sqrt{\\mathbb{E}[g_{t}^2]+\\epsilon}} \\cdot g_t\\label{eq:9}\\end{equation}$$ $$ \\begin{equation}\\theta_t = \\theta_{t-1} + \\Delta \\theta_{t}\\label{eq:10}\\end{equation}$$ 这样解决了学习率是超参数的问题，但是由于式$(9)$是一个累加的过程，导致自适应学习率越来越大，在训练后期，在局部最小值附近抖动 算法与证明Adam（Adaptive Moment Estimation）我理解是改进了Adadelta中式$(9)$中累加的问题，而用相似的期望的方式代替：$$ \\begin{equation}m_t = \\beta_1\\cdot m_{t-1}+(1-\\beta_1)\\cdot g_t\\label{eq:11}\\end{equation}$$也可以理解为用动量的累加自适应代替学习率，结合了Momentum，加快了算法的收敛速度，二阶矩的估计与式$(8)$相似：$$ \\begin{equation}v_t = \\beta _2\\cdot v_{t-1}+(1-\\beta _2)\\cdot g_t^2\\label{eq:12}\\end{equation}$$但是当初始化的$m_0$、$m_0$都为0，且$\\beta_1$、$\\beta_2$都接近1时，$m_t$、$v_t$近似等于零，这是因为$m_t$、$v_t$实际上是对$g_t$、$g_t^2$的有偏估计，证明在论文中，结果如式$(13)$：$$ \\begin{equation}\\mathbb{E}[v_t] = \\mathbb{E}[g_t^2]\\cdot (1-\\beta_2^t)+\\zeta\\label{eq:13}\\end{equation}$$故令：$$ \\begin{equation}\\hat{m_t} = m_t/(1-\\beta _1^t)\\label{eq:14}\\end{equation}$$ $$ \\begin{equation}\\hat{v_t} = v_t/(1-\\beta _2^t)\\label{eq:15}\\end{equation}$$这样$\\hat{m_t}$、$\\hat{v_t}$为$g_t$、$g_t^2$的无偏估计，又因为：$$ \\begin{equation}\\frac{\\mathbb{E}[g_t]^2}{\\mathbb{E}[g_t^2]} \\leq 1\\label{eq:16}\\end{equation}$$故学习率总小于$\\alpha$，控制了学习率不会过大。 结果与优点Adadelta，RMSprop，Adam是比较相近的算法，在相似的情况下表现差不多。Adam结合了Adagrad善于处理稀疏梯度和RMSprop善于处理非平稳目标的优点、也适用于大多非凸优化，5适用于大数据集和高维空间。论文中的结果证明，Adam的收敛速度很快。这是逻辑回归的损失函数下降图： 这是多层神经网络的损失函数下降图 最后附上两张著名的动图，应该是出自李菲菲教授的CS231：","tags":[{"name":"neural network","slug":"neural-network","permalink":"http://yoursite.com/tags/neural-network/"},{"name":"Adam","slug":"Adam","permalink":"http://yoursite.com/tags/Adam/"},{"name":"optimization","slug":"optimization","permalink":"http://yoursite.com/tags/optimization/"}]},{"title":"IMPROVED MUSICAL ONSET DETECTION WITH CONVOLUTIONAL NEURAL NETWORKS 阅读笔记","date":"2017-06-07T01:45:10.000Z","path":"2017/06/07/IMPROVED-MUSICAL-ONSET-DETECTION-WITH-CONVOLUTIONAL-NEURAL-NETWORKS-阅读笔记/","text":"本文是IMPROVED MUSICAL ONSET DETECTION WITH CONVOLUTIONAL NEURAL NETWORKS的阅读笔记，论文探索了CNN在音符开始时间探测的应用，采用100分钟，具有26K标记点的数据集，分析了CNN中各层的内在含义，总结了CNN探测音符onset的两点优势： 用不同的探测器分别检测打击乐的onset以及和声乐的onset 在同一个算法中，综合许多微小变量的值 引言类比图像边缘检测，在图像中高亮锋利边缘仅仅需要局部的图像信息以及一个较小的卷积核，如下图所示，一个灰度图像卷积随机的$5\\times 5$卷积核即可得到图像的边缘： 模型模型的结构如图所示： 数据预处理数据预处理为：将音频由44.1kHz采样到16kHz，计算了跳跃长度为10ms，窗口长为23ms、46ms和93ms的三幅频谱图，并经过80-band的Mel滤波器，归一化频谱参数，使其0均值1方差。模型的输入为15帧数据。 模型训练MIDI-batch为256，100次迭代，固定的学习率为0.05，初始动量为0.45.数据采用dropout，训练集的软处理，即在最靠近onset的$\\pm 7$帧（共15帧）都被认为是正样本。个人认为不如用高斯曲线拟合。同时卷积层的激活函数采用relu。训练的结果如图： 可见，CNN的结果要比人工设计的算法SuoerFlux好很多。 模型分析为了简化分析移除第二层卷积层，只保留第一层 输出层输出层共256个神经元，如图所示，将神经元按权值由辅导正的顺序排列在图中，下图依次为两个输入波形的频谱图（窗口长为46ms），神经网络的输出以及ground truth，和输出层256个神经元的激活情况。 如上图所示，大多数强连接神经元，即权重绝对值较大的神经元并没有被激活，他们可能专门用于处理训练集中的特殊情况。一些正神经元探测敲击onset开始，相对应的另一幅图的一些神经元探测和声onset的开始。 全连接层我们定位到了离信号改变较近的神经元，并可视化与这些神经元相连的feature map，如下如所示，即为两种典型的feature map的权重： 如上图所示共有上下两组权重，第二组的第四幅图可以明显的看到快速的正负正负的权值变化，有利于探测短时间的频域变化，即打击乐的onset。而第一组的第一幅和第九幅图可以看到缓慢的正负变化，有利于探测长时间的频谱变化，及和声乐onset。 卷积层我们定位map4和map9，下图一左即为第一个信号经过map4的值，下图一右为第二个信号经过map9的值。可以看出，在onset时刻，map的值有了变化。下图二为map4和map9对应的卷积核（依次为中短长窗口）。可以看到map4的卷积核探测频谱变化较快的点，而map9的卷积核探测变化较慢的点。","tags":[{"name":"CNN","slug":"CNN","permalink":"http://yoursite.com/tags/CNN/"},{"name":"music note detection","slug":"music-note-detection","permalink":"http://yoursite.com/tags/music-note-detection/"}]},{"title":"music note onset detection 论文阅读","date":"2017-06-05T12:37:08.000Z","path":"2017/06/05/music-note-detection-论文阅读/","text":"本文是NOTE ONSET DETECTION IN MUSICAL SIGNALS VIA NEURAL–NETWORK–BASED MULTI–ODF FUSION的阅读笔记。本文主要将ODF：onset detection function与神经网络结合起来，做music note onset的检测。 开始事件检测函数ODF：Onset detection function方法1本文的方法基本上是基于STFT变换，公式$(1)$是基于能量变化做的检测：$$ \\begin{equation}SF(n) = \\sum_{k}hwr(|X_k(n)|-|X_k(n-1)|)\\label{eq:1}\\end{equation}$$其中$X_k(n)$是第n帧的STFT的第k个值，这个值为复数代表幅度与相位信息这里取绝对值，只考虑能量信息，且：$$\\begin{equation}hwr(x) = \\frac{x+|x|}{2}\\label{eq:2}\\end{equation}$$$hwr(x)$即为半波整流函数（half-wave rectifier）仅当$x$为正数时，才有值。这样既可检测能量的突然增加。 方法2相位的变化可用式$(3)$表示：$$\\begin{equation}d\\varphi_k(n) = princarg[\\varphi_k(n)-2\\varphi_k(n-1)+\\varphi_k(n-2)]\\label{eq:3}\\end{equation}$$ 在$WPD(n)$同时考虑了幅度和相位的信息，故：$$\\begin{equation}WPD(n) = \\sum_{k}|hwr(|X_k(n)|-|X_k(n-1)|)\\cdot d\\varphi_k(n)\\label{eq:4}\\end{equation}$$ 方法3一种基于相位谱的更复杂的方法，他们使用相位偏差系数来构建每个STFT帧的相位偏移的二维直方图。 然后可以用一些统计特征来计算结果（例如，峰度）：$$\\begin{equation}PHK(n) = Kurt(h(d\\varphi_k(n)))\\label{eq:5}\\end{equation}$$ 方法4本方法直接在复频谱域进行计算，兼顾了相位与幅度：$$\\begin{equation}CD(n) = \\sum_{k}|\\widehat{S}_k(n)-S_k(n)|\\label{eq:6}\\end{equation}$$其中$|\\widehat{S}_k(n)-S_k(n)|$表示第n个STFT帧第k个频率仓的期望和实际之间的复数差的幅度，其中：$$\\begin{equation}\\widehat{S}_k(n) = |S_k(n-1)|e^{j(2\\varphi_k(n-1)-\\varphi_k(n-2))}\\label{eq:7}\\end{equation}$$以上三种方法皆为传统的ODF，在计算后加上固定的阈值即可检测onset。 混合模型如图所示即为混合模型的整体架构： 模型的输入为：$$\\begin{equation}\\boldsymbol x(n) = [\\boldsymbol v_S(n),\\boldsymbol v_W(n),\\boldsymbol v_P(n),\\boldsymbol v_C(n)]\\label{eq:8}\\end{equation}$$ 其中：$$\\begin{equation}\\boldsymbol v_{S}(n) = [SF(n-2),\\,SF(n-1),\\,SF(n),\\,SF(n+1),\\,SF(n+2),\\,\\overline{SF}(n)]\\label{eq:9}\\end{equation}$$ 其中：$$\\begin{equation}\\overline{SF}(n) = \\sum_{k=n-\\lfloor n_m/2\\rfloor}^{n+\\lfloor n_m/2\\rfloor}SF(k) \\qquad n_m = 21\\label{eq:10}\\end{equation}$$ 模型的输出为$P(onset\\,\\, \\vert n=k)$。由于onset时刻的两边也可以但测到onset，故label的生成采用软条件（soft condition），其中网络的目标输出值为以第n帧为中心的高斯曲线。 在一些简化和舍入之后，将出现在第n帧中的开始的连续目标值设置为:\\begin{equation}\\begin{aligned}t(n) &amp;= 0.75, \\\\t(n\\pm 1) &amp;= 0.55,\\\\t(n\\pm 2) &amp;= 0.35,\\\\t(n\\pm 3) &amp;= 0.25,\\\\t(n\\pm 4) &amp;= 0.25,\\\\\\end{aligned}\\end{equation}曲线如图所示： 神经网络的输出也被当成另一个ODF的输入，这个ODF用峰值检测以及固定的阈值检测onset的时间点。 模型训练及结果在分割训练集与测试集时，文章采用两种方案： 每次训练时，都移除一种乐器，用其余的16中乐器进行训练，被移除的乐器做测试集用，依次重复17次。把单独的音频文件分成10分，每一份都依次做交叉验证集使用，其余9份做训练集用。 以下分别为两种方案的结果： scheme 1 scheme 2 注意：有的乐器的特性与主流的乐器不同，其中一个严重的问题就在于单簧管和萨克斯的实际onset时刻会比记录的ground true晚很多，降低了第一种方案训练的准确性。各乐器的最佳偏移量如下图所示，评价标准为F-measure。 文章通过试验，找到了较好的神经网络输出的阈值以及特征值的子集，最终的结果为：","tags":[{"name":"music note detection","slug":"music-note-detection","permalink":"http://yoursite.com/tags/music-note-detection/"},{"name":"neural network","slug":"neural-network","permalink":"http://yoursite.com/tags/neural-network/"},{"name":"ODF","slug":"ODF","permalink":"http://yoursite.com/tags/ODF/"}]},{"title":"tensorflow.train.learning_rate_decay()","date":"2017-03-20T14:01:43.000Z","path":"2017/03/20/tensorflow-train-learning-rate-decay/","text":"学习udacity/3_regularization.ipynb时，发现tf.train.exponential_decay()函数，阅读源码，大概知道意思： 源码截取如下： 1234567891011121314151617def exponential_decay(learning_rate, global_step, decay_steps, decay_rate, staircase=False, name=None): if global_step is None: raise ValueError(\"global_step is required for exponential_decay.\") with ops.name_scope(name, \"ExponentialDecay\", [learning_rate, global_step, decay_steps, decay_rate]) as name: learning_rate = ops.convert_to_tensor(learning_rate, name=\"learning_rate\") dtype = learning_rate.dtype global_step = math_ops.cast(global_step, dtype) decay_steps = math_ops.cast(decay_steps, dtype) decay_rate = math_ops.cast(decay_rate, dtype) p = global_step / decay_steps if staircase: p = math_ops.floor(p) return math_ops.multiply(learning_rate, math_ops.pow(decay_rate, p), name=name) 看注释及代码可知 $$decayed\\ learning\\ rate = learning\\ rate \\times decay\\ rate ^ {global\\ step / decay\\ steps}$$ 即每隔global_step步进行一次递减，递减的方式为上一个learing_rate乘上decay_rate。由此可见，使用该方法下降learning_rate可使其迅速减小。 同时在Problem 4中，我使用了5层神经网络，用了L2正则以及dropout。我发现增加网络的层数并没有显著提高正确率，增加batch_size却可以提高正确率至96.4%。","tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://yoursite.com/tags/tensorflow/"},{"name":"Machine learning","slug":"Machine-learning","permalink":"http://yoursite.com/tags/Machine-learning/"}]},{"title":"Bug日记","date":"2017-03-13T10:24:50.000Z","path":"2017/03/13/Bug日记/","text":"得到了一个iPod并希望在上面调试程序，但是总是显示App installation failed - There was an error communicating with your device.在官网上并没有搜索在解决方案。最后将iPod强行恢复出厂设置，bug fix！","tags":[{"name":"iOS","slug":"iOS","permalink":"http://yoursite.com/tags/iOS/"}]},{"title":"制作POP翻页动画","date":"2016-07-26T12:16:59.000Z","path":"2016/07/26/制作POP翻页动画/","text":"我利用了POP库制作了简单的广告展示的翻页效果： yanshi 源码在这里 大致思路首先简单分析一下动画效果：我们使用了旋转以及平移两个动画效果，通过动图可以看到：通过手指拖动(pan)，图片在平移的同时绕着自身中轴线旋转。那么怎么让图片绕着中轴线旋转呢？可以使用POPBasicAnimation中的kPOPLayerRotaionY制作旋转动画，中轴线的位置为锚点的位置，可以通过anchorPoint、anchorPointZ以及position共同确定锚点的三维坐标。至于anchorPoint与position如何共同确定绝对坐标可以参照博客，简单来说：锚点是标志一个layer位置的点，anchorPoint是锚点在该layer的相对坐标，而positon是锚点在superView中的绝对坐标。沿x轴的平移效果可以通过POPBasicAnimaition的kPOPLayerPositionX来实现。旋转的角度以及平移的距离都与手指拖动(pan)的距离有关。 源码分析首先初始化五张图片，设置不同的位置，以及不同的旋转角度。在画面中只显示3张，但为了左右拖动时有图片补位，这里初始化5张。 12345678910111213141516171819202122- (void)initPictures &#123; for (int i = 0; i&lt;5; i++) &#123; UIImageView *imgView = [[UIImageView alloc]initWithImage:[UIImage imageNamed:[pictureNames objectAtIndex:i]]]; imgView.frame = CGRectMake(0, 0, 319, 187); imgView.layer.anchorPoint = CGPointMake(0.5, 0.5); imgView.layer.anchorPointZ = 100.0f; imgView.layer.position = CGPointMake(-62+i*287, 374/4+30); imgView.layer.transform = [self setTransform3D]; imgView.userInteractionEnabled = YES; POPBasicAnimation *initRotationAnimation = [POPBasicAnimation animationWithPropertyNamed:kPOPLayerRotationY]; initRotationAnimation.duration = 0; initRotationAnimation.toValue = @((2-i)*M_PI/6); [imgView.layer pop_addAnimation:initRotationAnimation forKey:@&quot;initRotation&quot;]; [self showImageAndReflection:imgView]; [imgViews addObject:imgView]; [self.view addSubview:imgView]; &#125;&#125; 这里通过showImageAndReflection函数来设置图片的倒影： 12345678910111213141516171819202122232425262728293031- (void)showImageAndReflection:(UIImageView *)view &#123; // 制作reflection CALayer *layer = view.layer; CALayer *reflectLayer = [CALayer layer]; reflectLayer.contents = layer.contents; reflectLayer.bounds = layer.bounds; reflectLayer.position = CGPointMake(layer.bounds.size.width/2, layer.bounds.size.height*1.5); reflectLayer.transform = CATransform3DMakeRotation(M_PI, 1, 0, 0); // 给该reflection加个半透明的layer CALayer *blackLayer = [CALayer layer]; blackLayer.backgroundColor = [UIColor whiteColor].CGColor; blackLayer.bounds = reflectLayer.bounds; blackLayer.position = CGPointMake(blackLayer.bounds.size.width/2, blackLayer.bounds.size.height/2); blackLayer.opacity = 0.6; [reflectLayer addSublayer:blackLayer]; // 给该reflection加个mask CAGradientLayer *mask = [CAGradientLayer layer]; mask.bounds = reflectLayer.bounds; mask.position = CGPointMake(mask.bounds.size.width/2, mask.bounds.size.height/2); mask.colors = [NSArray arrayWithObjects: (__bridge id)[UIColor clearColor].CGColor, (__bridge id)[UIColor whiteColor].CGColor, nil]; mask.startPoint = CGPointMake(0.5, 0.65); mask.endPoint = CGPointMake(0.5, 1); reflectLayer.mask = mask; // 作为layer的sublayer [layer addSublayer:reflectLayer];&#125; 代码参考这里 随后设置拖动手势UIPanGestureRecognizer并绑定panAllHandle函数，将手势绑定在当前view上。 12UIPanGestureRecognizer *panGesture = [[UIPanGestureRecognizer alloc]initWithTarget:self action:@selector(panAllHandle:)];[self.view addGestureRecognizer:panGesture]; 处理函数panAllHandle为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138- (void)panAllHandle:(UIPanGestureRecognizer *)recognizer &#123; CGPoint location = [recognizer locationInView:self.view]; if (recognizer.state == UIGestureRecognizerStateBegan) &#123; num = location.x; &#125; NSMutableArray *rotationAnimations = [[NSMutableArray alloc]init]; NSMutableArray *moveAnimations = [[NSMutableArray alloc]init]; NSMutableArray *rotationEndAnimations = [[NSMutableArray alloc]init]; NSMutableArray *moveEndAnimations = [[NSMutableArray alloc]init]; for (int i = 0; i&lt;5; i++) &#123; POPBasicAnimation *rotationAnimation = [POPBasicAnimation animationWithPropertyNamed:kPOPLayerRotationY]; rotationAnimation.duration = 0.01; POPBasicAnimation *moveAnimation = [POPBasicAnimation animationWithPropertyNamed:kPOPLayerPositionX]; moveAnimation.duration = 0.01; [rotationAnimations addObject:rotationAnimation]; [moveAnimations addObject:moveAnimation]; &#125; if (YES) &#123; CGFloat percent = M_PI / (6*287); POPBasicAnimation *rotationAnimation = [POPBasicAnimation animationWithPropertyNamed:kPOPLayerRotationY]; rotationAnimation.duration = 0.01; NSLog(@&quot;%f, %lu&quot;,location.x, (unsigned long)num); POPBasicAnimation *moveAnimation = [POPBasicAnimation animationWithPropertyNamed:kPOPLayerPositionX]; moveAnimation.duration = 0.01; if ((location.x-num)&gt;350) &#123; for (int i = 0; i&lt;4; i++) &#123; POPBasicAnimation *rotation = [rotationAnimations objectAtIndex:i]; rotation.toValue = @(-(350)*percent+(2-i)*M_PI/6); POPBasicAnimation *move = [moveAnimations objectAtIndex:i]; move.toValue = @(350-62+i*287); UIImageView *imgView = [imgViews objectAtIndex:i]; [imgView.layer pop_addAnimation:rotation forKey:@&quot;rotation&quot;]; [imgView.layer pop_addAnimation:move forKey:@&quot;move&quot;]; &#125; &#125; else if ((location.x-num)&lt;-350) &#123; for (int i = 1; i&lt;5; i++) &#123; POPBasicAnimation *rotation = [rotationAnimations objectAtIndex:i]; rotation.toValue = @(-(-350)*percent+(2-i)*M_PI/6); POPBasicAnimation *move = [moveAnimations objectAtIndex:i]; move.toValue = @(-350-62+i*287); UIImageView *imgView = [imgViews objectAtIndex:i]; [imgView.layer pop_addAnimation:rotation forKey:@&quot;rotation&quot;]; [imgView.layer pop_addAnimation:move forKey:@&quot;move&quot;]; &#125; &#125; else if ((location.x - num)&gt;0) &#123; for (int i = 0; i&lt;4; i++) &#123; POPBasicAnimation *rotation = [rotationAnimations objectAtIndex:i]; rotation.toValue = @(-(location.x-num)*percent+(2-i)*M_PI/6); POPBasicAnimation *move = [moveAnimations objectAtIndex:i]; move.toValue = @(location.x-num-62+i*287); UIImageView *imgView = [imgViews objectAtIndex:i]; [imgView.layer pop_addAnimation:rotation forKey:@&quot;rotation&quot;]; [imgView.layer pop_addAnimation:move forKey:@&quot;move&quot;]; &#125; &#125; else if ((location.x - num)&lt;=0) &#123; for (int i = 1; i&lt;5; i++) &#123; POPBasicAnimation *rotation = [rotationAnimations objectAtIndex:i]; rotation.toValue = @(-(location.x-num)*percent+(2-i)*M_PI/6); POPBasicAnimation *move = [moveAnimations objectAtIndex:i]; move.toValue = @(location.x-num-62+i*287); UIImageView *imgView = [imgViews objectAtIndex:i]; [imgView.layer pop_addAnimation:rotation forKey:@&quot;rotation&quot;]; [imgView.layer pop_addAnimation:move forKey:@&quot;move&quot;]; &#125; &#125; if (recognizer.state == UIGestureRecognizerStateEnded || recognizer.state == UIGestureRecognizerStateCancelled) &#123; for (int i = 0; i&lt;5; i++) &#123; POPSpringAnimation *recoverAnimation = [POPSpringAnimation animationWithPropertyNamed:kPOPLayerRotationY]; recoverAnimation.springBounciness = 18.0f; recoverAnimation.dynamicsMass = 2.0f; recoverAnimation.dynamicsTension = 200; POPSpringAnimation *recover = [POPSpringAnimation animationWithPropertyNamed:kPOPLayerPositionX]; recover.springBounciness = 18.0f; recover.dynamicsMass = 2.0f; recover.dynamicsTension = 200; [rotationEndAnimations addObject:recoverAnimation]; [moveEndAnimations addObject:recover]; &#125; POPSpringAnimation *recoverAnimation = [POPSpringAnimation animationWithPropertyNamed:kPOPLayerRotationY]; recoverAnimation.springBounciness = 18.0f; recoverAnimation.dynamicsMass = 2.0f; recoverAnimation.dynamicsTension = 200; // initialLocation = -img.frame.origin.x-img.frame.size.width/2; if ((location.x-num)&gt;50) &#123; for (int i = 0; i&lt;4; i++) &#123; POPBasicAnimation *rotation = [rotationEndAnimations objectAtIndex:i]; rotation.toValue = @(-(287)*percent+(2-i)*M_PI/6); POPBasicAnimation *move = [moveEndAnimations objectAtIndex:i]; move.toValue = @(287-62+i*287); UIImageView *imgView = [imgViews objectAtIndex:i]; [imgView.layer pop_addAnimation:rotation forKey:@&quot;rotation&quot;]; [imgView.layer pop_addAnimation:move forKey:@&quot;move&quot;]; &#125; [self moveRight]; &#125; else if ((location.x-num)&lt;-50) &#123; for (int i = 1; i&lt;5; i++) &#123; POPBasicAnimation *rotation = [rotationEndAnimations objectAtIndex:i]; rotation.toValue = @(-(-287)*percent+(2-i)*M_PI/6); POPBasicAnimation *move = [moveEndAnimations objectAtIndex:i]; move.toValue = @(-287-62+i*287); UIImageView *imgView = [imgViews objectAtIndex:i]; [imgView.layer pop_addAnimation:rotation forKey:@&quot;rotation&quot;]; [imgView.layer pop_addAnimation:move forKey:@&quot;move&quot;]; &#125; [self moveLeft]; &#125; else &#123; for (int i = 0; i&lt;5; i++) &#123; POPBasicAnimation *rotation = [rotationEndAnimations objectAtIndex:i]; rotation.toValue = @((2-i)*M_PI/6); POPBasicAnimation *move = [moveEndAnimations objectAtIndex:i]; move.toValue = @(-62+i*287); UIImageView *imgView = [imgViews objectAtIndex:i]; [imgView.layer pop_addAnimation:rotation forKey:@&quot;rotation&quot;]; [imgView.layer pop_addAnimation:move forKey:@&quot;move&quot;]; &#125; &#125; &#125; &#125;&#125; 由于重复的动画过多，这里只解释其中两种：初始化旋转以及平移函数,duration代表持续时间。 1234POPBasicAnimation *rotationAnimation = [POPBasicAnimation animationWithPropertyNamed:kPOPLayerRotationY];rotationAnimation.duration = 0.01;POPBasicAnimation *moveAnimation = [POPBasicAnimation animationWithPropertyNamed:kPOPLayerPositionX];moveAnimation.duration = 0.01; 通过position.x与num的差值，获得拖动的x轴方向距离。根据该距离设置好旋转动画旋转的角度，以及平移动画平移的距离。 12rotation.toValue = @(-(location.x-num)*percent+(2-i)*M_PI/6);move.toValue = @(location.x-num-62+i*287); 最后将动画绑定在图片上： 12[imgView.layer pop_addAnimation:rotation forKey:@&quot;rotation&quot;];[imgView.layer pop_addAnimation:move forKey:@&quot;move&quot;]; 这样一个图片的动画就完成了。最后推广在到所有图片上，并为拖动距离添加一定的阈值即可完成动画。","tags":[{"name":"iOS","slug":"iOS","permalink":"http://yoursite.com/tags/iOS/"},{"name":"POP","slug":"POP","permalink":"http://yoursite.com/tags/POP/"}]},{"title":"将cocos工程加入到iOS工程中","date":"2016-07-05T12:43:50.000Z","path":"2016/07/05/将cocos工程加入到iOS工程中/","text":"本文讨论的是这样一种情况：一个iOS应用中有一个游戏，iOS程序与游戏是单独开发，并且游戏是用cocos2dx引擎。这样在开发结束时，我们需要将这两个工程合到一起，换句话说就是讲cocos游戏嵌入到iOS应用中。 大致思路我的解决方案的大致思路是这样的：将cocos引擎添加到iOS工程中，在合适的位置进入cocos游戏界面。 步骤向iOS工程中加入文件首先按cocos官网上的方法生成cocos工程，向iOS工程中添加cocos工程中的Classes/、proj.ios_mac/ios/、resources复制到iOS工程的文件夹中。向工程中添加文件：Classes/、ios/、cocos2d/build/cocos2d_libs.xcodeproj。 更改工程设置1.向工程中添加如图所示的库 Markdown 2.向 Building Setting&gt;Header Search Paths 中添加项 Markdown 3.在 Building Setting 中更改工程设置 Markdown Markdown 4.删除原工程的 main.m、AppDelegate.h/m 文件 更改工程入口具体设置参照博客，大致的思路就是修改cocos工程的入口AppController文件，在需要嵌入游戏的位置初始化RootViewController即可。 合并后的工程在这里.","tags":[{"name":"iOS","slug":"iOS","permalink":"http://yoursite.com/tags/iOS/"},{"name":"cocos2dx","slug":"cocos2dx","permalink":"http://yoursite.com/tags/cocos2dx/"}]},{"title":"开始我的hexo博客","date":"2016-03-23T08:05:00.000Z","path":"2016/03/23/开始我的hexo博客/","text":"很早就有写博客的想法了，今天终于用hexo搭起了自己的博客，记录一下过程： 安装hexo使用nvm安装Node.js 1$ wget -qO- https://raw.github.com/creationix/nvm/master/install.sh | sh 安装完成后，重启终端并执行下列命令即可安装 Node.js 1$ nvm install 4 安装Hexo 1$ npm install -g hexo-cli 安装部署到git的插件 1$ npm install hexo-deployer-git --save 配置Github创建名为yourname.github.io的repository开启gh-pages功能 配置hexo按照hexo官网上的配置步骤进行注意配置_config.yml中的language选项时，需要看主题中language/里的语言文件 使用Next主题123$ cd theme/$ git clone https://github.com/iissnan/hexo-theme-next.git$ vim ../_config.yml 将theme:改为theme: hexo-theme-next 部署到Github修改配置完成后执行下列语句，生成代码 1$ hexo g 执行下列语句，部署到Github上 1$ hexo d","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]}]